{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rhea\n",
      "Modules imported \n",
      "\n",
      "Files in current directory:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import itemgetter    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils, to_categorical\n",
    " \n",
    "from keras.datasets import imdb\n",
    "\n",
    "print(os.getcwd())\n",
    "print(\"Modules imported \\n\")\n",
    "print(\"Files in current directory:\")\n",
    "from subprocess import check_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IMDB DATA\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "num_words=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data  (25000,)\n",
      "train_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "test_data  (25000,)\n",
      "test_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "Maximum value of a word index \n",
      "9999\n",
      "Maximum length num words of review in train \n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data \", train_data.shape)\n",
    "print(\"train_labels \", train_labels.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"test_data \", test_data.shape)\n",
    "print(\"test_labels \", test_labels.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"Maximum value of a word index \")\n",
    "print(max([max(sequence) for sequence in train_data]))\n",
    "print(\"Maximum length num words of review in train \")\n",
    "print(max([len(sequence) for sequence in train_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? beautiful and touching movie rich colors great settings good acting and one of the most charming movies i have seen in a while i never saw such an interesting setting when i was in china my wife liked it so much she asked me to ? on and rate it so other would enjoy too\n"
     ]
    }
   ],
   "source": [
    "# See an actual review in words\n",
    "# Reverse from integers to words using the DICTIONARY (given by keras...need to do nothing to create it)\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "reverse_word_index = dict(\n",
    "[(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "decoded_review = ' '.join(\n",
    "[reverse_word_index.get(i - 3, '?') for i in train_data[123]])\n",
    "\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTORIZE as one cannot feed integers into a NN \n",
    "# Encoding the integer sequences into a binary matrix - one hot encoder basically\n",
    "# From integers representing words, at various lengths - to a normalized one hot encoded tensor (matrix) of 10k columns\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train  (25000, 10000)\n",
      "x_test  (25000, 10000)\n"
     ]
    }
   ],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "print(\"x_train \", x_train.shape)\n",
    "print(\"x_test \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train  (25000,)\n",
      "y_test  (25000,)\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZE the labels too - NO INTEGERS only floats into a tensor...(rare exceptions)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "print(\"y_train \", y_train.shape)\n",
    "print(\"y_test \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val  (10000, 10000)\n",
      "partial_x_train  (15000, 10000)\n",
      "y_val  (10000,)\n",
      "partial_y_train  (15000,)\n"
     ]
    }
   ],
   "source": [
    "# Set a VALIDATION set\n",
    "\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(\"x_val \", x_val.shape)\n",
    "print(\"partial_x_train \", partial_x_train.shape)\n",
    "print(\"y_val \", y_val.shape)\n",
    "print(\"partial_y_train \", partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN MODEL\n",
    "\n",
    "# Use of DROPOUT\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.001), activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.001),activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Use of REGULARIZATION\n",
    "#model = models.Sequential()\n",
    "#model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu', input_shape=(10000,)))\n",
    "#model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu'))\n",
    "#model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# REGULARIZERS L1 L2\n",
    "#regularizers.l1(0.001)\n",
    "#regularizers.l2(0.001)\n",
    "#regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "# OPTIMIZERS\n",
    "#model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\n",
    "#model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.6689 - acc: 0.8387 - val_loss: 0.5566 - val_acc: 0.8697\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.6154 - acc: 0.8497 - val_loss: 0.5470 - val_acc: 0.8665\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 1s 96us/step - loss: 0.6140 - acc: 0.8532 - val_loss: 0.5487 - val_acc: 0.8706\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.6051 - acc: 0.8567 - val_loss: 0.5473 - val_acc: 0.8717\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.6067 - acc: 0.8524 - val_loss: 0.5477 - val_acc: 0.8705\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.6002 - acc: 0.8615 - val_loss: 0.5375 - val_acc: 0.8733\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.6055 - acc: 0.8535 - val_loss: 0.5971 - val_acc: 0.8407\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.6138 - acc: 0.8517 - val_loss: 0.5908 - val_acc: 0.8477\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.6054 - acc: 0.8564 - val_loss: 0.5623 - val_acc: 0.8633\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 1s 96us/step - loss: 0.6047 - acc: 0.8580 - val_loss: 0.5494 - val_acc: 0.8685\n",
      "25000/25000 [==============================] - 2s 67us/step\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# FIT / TRAIN model\n",
    "\n",
    "NumEpochs = 10\n",
    "BatchSize = 512\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"_\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss and Accuracy\n",
      "results  [0.5502808885288238, 0.8647599816322327]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss and Accuracy\")\n",
    "print(\"results \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
